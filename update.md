# 更新日志
* v0.2.0
    * ui全面焕新，更动态更好看，为api key显示添加分页，适配拥有大量key的用户
    * 隔离vertex模式与ai studio模式日志，ai studio玩家再也不会看到vertex的报错了
    * 拆分web ui密码与连接密码，现在可以安全的把反代分享给其他人了
    * 新增环境变量`WEB_PASSWORD`，为web ui修改设置密码，默认值为环境变量`PASSWORD`的值
    * 修复若干bug，增加系统稳定性
* v0.1.7
    * 添加token计数器，现在可以在前端看到每一个api使用的token数与单模型使用的token数量了
    * 为2.5flash模型适配`thinkingBudget`参数，用户只需在附加参数中添加`- thinking_budget : 1024`即可调整
    * 修复在报错中错误漏出key的问题
    * 为并发缓存功能实现缓存键值计算切换，用户可选择使用最后四条消息或全部消息计算缓存
    * 新增环境变量`PRECISE_CACHE`，为切换缓存计算方法，默认为`false`
    * 修复若干bug
* v0.1.6
    * 为并发模式提供缓存，并发中除了返回的成功请求，其他成功请求将被缓存，若下次请求与本次请求一致，将首先使用缓存内容
    * 为请求添加硬限制，超过每日限定次数的key将不再发送请求，若所有key都达到次数限制，将随机选择一个key请求
    * 添加空响应计数，单次请求空响应重试超过一定次数将直接跳出
    * 修复联网模式bug（感谢**yoolieer**），现在能够正常的启用停用联网模式了
    * 新增环境变量`MAX_EMPTY_RESPONSES`，为空响应重试次数，默认为5
    * 修复若干bug
* v0.1.5
    * 实现vertex热切换，现在在前端面板就可以切换vertex模式与ai studio模式了
    * 为vertex模式实现假流式，环境变量与ai studio模式的假流式相同，均为`FAKE_STREAMING`
    * 优化前端界面
    * 修复若干bug
* v0.1.4beta
    * 为大部分配置项适配热更新，可实时调整配置
    * 前端界面新增适配热更新相关ui界面，可直接调整配置（在前端界面修改的数据在重启后会失效）
    * 适配 vertex ai（基于gzzhongqi/vertex2openai项目开发），在启用vertex模式并配置vertex凭证后，项目将切换为vertex请求模式
    * 新增环境变量`ENABLE_VERTEX`用于启用vertex模式，初始默认为false
    * 新增环境变量`GOOGLE_CREDENTIALS_JSON`用于配置vertex凭证，默认为空
* v0.1.3
    * 应对谷歌加强封锁紧急更新，优化连接逻辑，减少错误发生
    * 修复了在非流式模式下日志暴露key的问题
    * 修复前端界面联网模式无法正确显示
    * 修复前端界面伪装模式字符数量无法正确显示
* v0.1.2beta
    * 为非流式和假流式传输模式新增动态并发功能，用户可自定义初始并发请求数。在全部请求失败时，系统将增加并发请求数，直至达到最大并发请求数。当收到请求时，程序会首先尝试并发处理，若并发处理失败，则根据设定逐步增加并发数。
    * 重构请求处理逻辑，现在能够正确处理各个模式的请求。
    * 新增手动重置统计数据按钮，用户可在点击按钮后输入password重置统计数据
    * 前端环境配置栏目将展示更多功能配置，同时展示卡可折叠
    * 修改重置统计数据时间为北京时间15点
    * 修复若干bug
    * 新增环境变量`CONCURRENT_REQUESTS`用于设置默认的并发请求数，初始默认值为1。
    * 新增环境变量`INCREASE_CONCURRENT_ON_FAILURE`用于设置当请求失败时增加的并发请求数，初始默认值为1。
    * 新增环境变量`MAX_CONCURRENT_REQUESTS`用于设置允许的最大并发请求数，初始默认值为3。
*   v0.1.1
    * 新增联网模式,为所有gemini2.x模型提供联网能力，在模型列表中选择-search后缀的模型启用
    * 新增环境变量`SEARCH_MODE`是否启用联网模式，默认为true
    * 新增环境变量`SEARCH_PROMPT`为联网模式提示词，默认为`（使用搜索工具联网搜索，需要在content中结合搜索内容）`
*   v0.1.0
    * 使用vue重写前端界面，适配移动端
    * 前端界面添加黑夜模式
    * 支持为多模态模型上传图片
    * 可用秘钥数量将异步更新，防止阻塞进程
    * 这次真能北京时间16点自动重置统计数据了
    * 为api秘钥使用统计新增模型使用统计，可分别统计使用不同模型的次数
    * 修改默认api可用次数为100次
    * 降低默认伪装信息长度为5，以减少对上下文的污染
*   v0.0.5beta
    * 新增"**伪装信息**功能，默认开启，可在转发消息中添加随机字符串伪装消息，防止被检测
    * 修复若干bug
    * 为前端界面新增**功能配置**栏目，可检查功能是否开启
    * 北京时间16点自动重置统计数据
    * 在环境变量中新增`RANDOM_STRING`，是否启用伪装信息，默认值为true
    * 在环境变量中新增`RANDOM_STRING_LENGTH`，伪装信息长度，默认为20
    * 为git用户提供单独的`Dockerfile_git`
*   v0.0.4
    * 修改版本更新逻辑，现在为每四小时检查一次版本更新
    * 前端界面所有数据数据实现动态更新
    * 新增**单api使用次数统计**，在原API调用统计下方新增可折叠的单api使用次数统计，同时提供进度条查看剩余使用次数
    * 在环境变量中新增`API_KEY_DAILY_LIMIT`，为单api 24小时最大使用次数，默认值为25
    * 在环境变量中新增`BLOCKED_MODELS`，为需要屏蔽的模型名称，多个模型用英文逗号分隔
*   v0.0.3beta
    * 完善了客户端断开连接的处理逻辑（感谢[@warming-afternoon](https://github.com/warming-afternoon)）
    * 新增"假流式传输模式"，该模式默认开启，以解决在某些情况下客户端断开连接的问题。如需关闭，请将环境变量 `FAKE_STREAMING` 设置为 `false`。
*   v0.0.2 修复了在log中错误暴露apikey的问题，修改了客户端断开连接的处理逻辑（感谢[@warming-afternoon](https://github.com/warming-afternoon)）